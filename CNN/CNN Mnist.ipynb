{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pandas as pd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = (0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv', header=0);\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_train, ratio_validate, ratio_test = split;\n",
    "\n",
    "cols = list(data.columns.values)\n",
    "cols.remove('label')\n",
    "\n",
    "X = data.as_matrix(cols)\n",
    "y = data['label'].values\n",
    "\n",
    "\n",
    "rows_num = data.values.shape[0]\n",
    "num_train = rows_num*ratio_train\n",
    "num_validate = rows_num*ratio_validate\n",
    "num_test = rows_num*ratio_test\n",
    "\n",
    "train_set = (X[0:num_train], y[0:num_train]);\n",
    "valid_set = (X[num_train:num_train+num_validate], y[num_train:num_train+num_validate]);\n",
    "test_set = (X[num_train+num_validate:rows_num], y[num_train+num_validate:rows_num]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_set, valid_set, test_set format: tuple(input, target)\n",
    "#input is an numpy.ndarray of 2 dimensions (a matrix)\n",
    "#witch row's correspond to an example. target is a\n",
    "#numpy.ndarray of 1 dimensions (vector)) that have the same length as\n",
    "#the number of rows in the input. It should give the target\n",
    "#target to the example with the same index in the input.\n",
    "\n",
    "def shared_dataset(data_xy, borrow=True):\n",
    "    \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "    The reason we store our dataset in shared variables is to allow\n",
    "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    is needed (the default behaviour if the data is not in a shared\n",
    "    variable) would lead to a large decrease in performance.\n",
    "    \"\"\"\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                           dtype=theano.config.floatX),\n",
    "                             borrow=borrow)\n",
    "    shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                           dtype=theano.config.floatX),\n",
    "                             borrow=borrow)\n",
    "    # When storing data on the GPU it has to be stored as floats\n",
    "    # therefore we will store the labels as ``floatX`` as well\n",
    "    # (``shared_y`` does exactly that). But during our computations\n",
    "    # we need them as ints (we use labels as index, and if they are\n",
    "    # floats it doesn't make sense) therefore instead of returning\n",
    "    # ``shared_y`` we will have to cast it to int. This little hack\n",
    "    # lets ous get around this issue\n",
    "\n",
    "    #return shared_x, T.cast(shared_y, 'float32')\n",
    "    return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "test_set_x, test_set_y = shared_dataset(test_set)\n",
    "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),\n",
    "        (test_set_x, test_set_y)]\n",
    "\n",
    "datasets = rval\n",
    "n_in = len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_bias_variance_data(filename, list1, list2, list3):    \n",
    "    import csv\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        csv_data = zip(list1, list2, list3)\n",
    "        writer.writerows(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "lin_output :  TensorType(float32, matrix) 2\n",
      "... training\n",
      "training @ iter =  0\n",
      "training @ iter =  100\n",
      "training @ iter =  200\n",
      "epoch 1, minibatch 293/293, validation error 4.095238 %\n",
      "     epoch 1, minibatch 293/293, test error of best model 4.595238 %\n",
      "training @ iter =  300\n",
      "training @ iter =  400\n",
      "training @ iter =  500\n",
      "epoch 2, minibatch 293/293, validation error 3.011905 %\n",
      "     epoch 2, minibatch 293/293, test error of best model 3.285714 %\n",
      "training @ iter =  600\n",
      "training @ iter =  700\n",
      "training @ iter =  800\n",
      "epoch 3, minibatch 293/293, validation error 2.380952 %\n",
      "     epoch 3, minibatch 293/293, test error of best model 2.785714 %\n",
      "training @ iter =  900\n",
      "training @ iter =  1000\n",
      "training @ iter =  1100\n",
      "epoch 4, minibatch 293/293, validation error 2.297619 %\n",
      "     epoch 4, minibatch 293/293, test error of best model 2.714286 %\n",
      "training @ iter =  1200\n",
      "training @ iter =  1300\n",
      "training @ iter =  1400\n",
      "epoch 5, minibatch 293/293, validation error 2.107143 %\n",
      "     epoch 5, minibatch 293/293, test error of best model 2.333333 %\n",
      "training @ iter =  1500\n",
      "training @ iter =  1600\n",
      "training @ iter =  1700\n",
      "epoch 6, minibatch 293/293, validation error 1.869048 %\n",
      "     epoch 6, minibatch 293/293, test error of best model 2.047619 %\n",
      "training @ iter =  1800\n",
      "training @ iter =  1900\n",
      "training @ iter =  2000\n",
      "epoch 7, minibatch 293/293, validation error 1.690476 %\n",
      "     epoch 7, minibatch 293/293, test error of best model 1.738095 %\n",
      "training @ iter =  2100\n",
      "training @ iter =  2200\n",
      "training @ iter =  2300\n",
      "epoch 8, minibatch 293/293, validation error 1.535714 %\n",
      "     epoch 8, minibatch 293/293, test error of best model 1.785714 %\n",
      "training @ iter =  2400\n",
      "training @ iter =  2500\n",
      "training @ iter =  2600\n",
      "epoch 9, minibatch 293/293, validation error 1.607143 %\n",
      "training @ iter =  2700\n",
      "training @ iter =  2800\n",
      "training @ iter =  2900\n",
      "epoch 10, minibatch 293/293, validation error 1.416667 %\n",
      "     epoch 10, minibatch 293/293, test error of best model 1.285714 %\n",
      "training @ iter =  3000\n",
      "training @ iter =  3100\n",
      "training @ iter =  3200\n",
      "epoch 11, minibatch 293/293, validation error 1.666667 %\n",
      "training @ iter =  3300\n",
      "training @ iter =  3400\n",
      "training @ iter =  3500\n",
      "epoch 12, minibatch 293/293, validation error 1.714286 %\n",
      "training @ iter =  3600\n",
      "training @ iter =  3700\n",
      "training @ iter =  3800\n",
      "epoch 13, minibatch 293/293, validation error 1.440476 %\n",
      "training @ iter =  3900\n",
      "training @ iter =  4000\n",
      "training @ iter =  4100\n",
      "epoch 14, minibatch 293/293, validation error 1.547619 %\n",
      "training @ iter =  4200\n",
      "training @ iter =  4300\n",
      "epoch 15, minibatch 293/293, validation error 1.357143 %\n",
      "     epoch 15, minibatch 293/293, test error of best model 1.404762 %\n",
      "training @ iter =  4400\n",
      "training @ iter =  4500\n",
      "training @ iter =  4600\n",
      "epoch 16, minibatch 293/293, validation error 1.392857 %\n",
      "training @ iter =  4700\n",
      "training @ iter =  4800\n",
      "training @ iter =  4900\n",
      "epoch 17, minibatch 293/293, validation error 1.392857 %\n",
      "training @ iter =  5000\n",
      "training @ iter =  5100\n",
      "training @ iter =  5200\n",
      "epoch 18, minibatch 293/293, validation error 1.357143 %\n",
      "training @ iter =  5300\n",
      "training @ iter =  5400\n",
      "training @ iter =  5500\n",
      "epoch 19, minibatch 293/293, validation error 1.273810 %\n",
      "     epoch 19, minibatch 293/293, test error of best model 1.285714 %\n",
      "training @ iter =  5600\n",
      "training @ iter =  5700\n",
      "training @ iter =  5800\n",
      "epoch 20, minibatch 293/293, validation error 1.154762 %\n",
      "     epoch 20, minibatch 293/293, test error of best model 1.166667 %\n",
      "training @ iter =  5900\n",
      "training @ iter =  6000\n",
      "training @ iter =  6100\n",
      "epoch 21, minibatch 293/293, validation error 1.166667 %\n",
      "training @ iter =  6200\n",
      "training @ iter =  6300\n",
      "training @ iter =  6400\n",
      "epoch 22, minibatch 293/293, validation error 1.166667 %\n",
      "training @ iter =  6500\n",
      "training @ iter =  6600\n",
      "training @ iter =  6700\n",
      "epoch 23, minibatch 293/293, validation error 1.238095 %\n",
      "training @ iter =  6800\n",
      "training @ iter =  6900\n",
      "training @ iter =  7000\n",
      "epoch 24, minibatch 293/293, validation error 1.190476 %\n",
      "training @ iter =  7100\n",
      "training @ iter =  7200\n",
      "training @ iter =  7300\n",
      "epoch 25, minibatch 293/293, validation error 1.154762 %\n",
      "training @ iter =  7400\n",
      "training @ iter =  7500\n",
      "training @ iter =  7600\n",
      "epoch 26, minibatch 293/293, validation error 1.202381 %\n",
      "training @ iter =  7700\n",
      "training @ iter =  7800\n",
      "training @ iter =  7900\n",
      "epoch 27, minibatch 293/293, validation error 1.178571 %\n",
      "training @ iter =  8000\n",
      "training @ iter =  8100\n",
      "training @ iter =  8200\n",
      "epoch 28, minibatch 293/293, validation error 1.202381 %\n",
      "training @ iter =  8300\n",
      "training @ iter =  8400\n",
      "epoch 29, minibatch 293/293, validation error 1.154762 %\n",
      "training @ iter =  8500\n",
      "training @ iter =  8600\n",
      "training @ iter =  8700\n",
      "epoch 30, minibatch 293/293, validation error 1.238095 %\n",
      "training @ iter =  8800\n",
      "training @ iter =  8900\n",
      "training @ iter =  9000\n",
      "epoch 31, minibatch 293/293, validation error 1.166667 %\n",
      "training @ iter =  9100\n",
      "training @ iter =  9200\n",
      "training @ iter =  9300\n",
      "epoch 32, minibatch 293/293, validation error 1.250000 %\n",
      "training @ iter =  9400\n",
      "training @ iter =  9500\n",
      "training @ iter =  9600\n",
      "epoch 33, minibatch 293/293, validation error 1.166667 %\n",
      "training @ iter =  9700\n",
      "training @ iter =  9800\n",
      "training @ iter =  9900\n",
      "epoch 34, minibatch 293/293, validation error 1.178571 %\n",
      "training @ iter =  10000\n",
      "training @ iter =  10100\n",
      "training @ iter =  10200\n",
      "epoch 35, minibatch 293/293, validation error 1.142857 %\n",
      "     epoch 35, minibatch 293/293, test error of best model 1.357143 %\n",
      "training @ iter =  10300\n",
      "training @ iter =  10400\n",
      "training @ iter =  10500\n",
      "epoch 36, minibatch 293/293, validation error 1.166667 %\n",
      "training @ iter =  10600\n",
      "training @ iter =  10700\n",
      "training @ iter =  10800\n",
      "epoch 37, minibatch 293/293, validation error 1.130952 %\n",
      "     epoch 37, minibatch 293/293, test error of best model 1.309524 %\n",
      "training @ iter =  10900\n",
      "training @ iter =  11000\n",
      "training @ iter =  11100\n",
      "epoch 38, minibatch 293/293, validation error 1.130952 %\n",
      "training @ iter =  11200\n",
      "training @ iter =  11300\n",
      "training @ iter =  11400\n",
      "epoch 39, minibatch 293/293, validation error 1.130952 %\n",
      "training @ iter =  11500\n",
      "training @ iter =  11600\n",
      "training @ iter =  11700\n",
      "epoch 40, minibatch 293/293, validation error 1.107143 %\n",
      "     epoch 40, minibatch 293/293, test error of best model 1.333333 %\n",
      "training @ iter =  11800\n",
      "training @ iter =  11900\n",
      "training @ iter =  12000\n",
      "epoch 41, minibatch 293/293, validation error 1.154762 %\n",
      "training @ iter =  12100\n",
      "training @ iter =  12200\n",
      "training @ iter =  12300\n",
      "epoch 42, minibatch 293/293, validation error 1.071429 %\n",
      "     epoch 42, minibatch 293/293, test error of best model 1.261905 %\n",
      "training @ iter =  12400\n",
      "training @ iter =  12500\n",
      "epoch 43, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  12600\n",
      "training @ iter =  12700\n",
      "training @ iter =  12800\n",
      "epoch 44, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  12900\n",
      "training @ iter =  13000\n",
      "training @ iter =  13100\n",
      "epoch 45, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  13200\n",
      "training @ iter =  13300\n",
      "training @ iter =  13400\n",
      "epoch 46, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  13500\n",
      "training @ iter =  13600\n",
      "training @ iter =  13700\n",
      "epoch 47, minibatch 293/293, validation error 1.119048 %\n",
      "training @ iter =  13800\n",
      "training @ iter =  13900\n",
      "training @ iter =  14000\n",
      "epoch 48, minibatch 293/293, validation error 1.119048 %\n",
      "training @ iter =  14100\n",
      "training @ iter =  14200\n",
      "training @ iter =  14300\n",
      "epoch 49, minibatch 293/293, validation error 1.119048 %\n",
      "training @ iter =  14400\n",
      "training @ iter =  14500\n",
      "training @ iter =  14600\n",
      "epoch 50, minibatch 293/293, validation error 1.107143 %\n",
      "training @ iter =  14700\n",
      "training @ iter =  14800\n",
      "training @ iter =  14900\n",
      "epoch 51, minibatch 293/293, validation error 1.107143 %\n",
      "training @ iter =  15000\n",
      "training @ iter =  15100\n",
      "training @ iter =  15200\n",
      "epoch 52, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  15300\n",
      "training @ iter =  15400\n",
      "training @ iter =  15500\n",
      "epoch 53, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  15600\n",
      "training @ iter =  15700\n",
      "training @ iter =  15800\n",
      "epoch 54, minibatch 293/293, validation error 1.119048 %\n",
      "training @ iter =  15900\n",
      "training @ iter =  16000\n",
      "training @ iter =  16100\n",
      "epoch 55, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  16200\n",
      "training @ iter =  16300\n",
      "training @ iter =  16400\n",
      "epoch 56, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  16500\n",
      "training @ iter =  16600\n",
      "training @ iter =  16700\n",
      "epoch 57, minibatch 293/293, validation error 1.071429 %\n",
      "     epoch 57, minibatch 293/293, test error of best model 1.261905 %\n",
      "training @ iter =  16800\n",
      "training @ iter =  16900\n",
      "epoch 58, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  17000\n",
      "training @ iter =  17100\n",
      "training @ iter =  17200\n",
      "epoch 59, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  17300\n",
      "training @ iter =  17400\n",
      "training @ iter =  17500\n",
      "epoch 60, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  17600\n",
      "training @ iter =  17700\n",
      "training @ iter =  17800\n",
      "epoch 61, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  17900\n",
      "training @ iter =  18000\n",
      "training @ iter =  18100\n",
      "epoch 62, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  18200\n",
      "training @ iter =  18300\n",
      "training @ iter =  18400\n",
      "epoch 63, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  18500\n",
      "training @ iter =  18600\n",
      "training @ iter =  18700\n",
      "epoch 64, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  18800\n",
      "training @ iter =  18900\n",
      "training @ iter =  19000\n",
      "epoch 65, minibatch 293/293, validation error 1.071429 %\n",
      "training @ iter =  19100\n",
      "training @ iter =  19200\n",
      "training @ iter =  19300\n",
      "epoch 66, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  19400\n",
      "training @ iter =  19500\n",
      "training @ iter =  19600\n",
      "epoch 67, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  19700\n",
      "training @ iter =  19800\n",
      "training @ iter =  19900\n",
      "epoch 68, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  20000\n",
      "training @ iter =  20100\n",
      "training @ iter =  20200\n",
      "epoch 69, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  20300\n",
      "training @ iter =  20400\n",
      "training @ iter =  20500\n",
      "epoch 70, minibatch 293/293, validation error 1.083333 %\n",
      "training @ iter =  20600\n",
      "training @ iter =  20700\n",
      "training @ iter =  20800\n",
      "epoch 71, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  20900\n",
      "training @ iter =  21000\n",
      "epoch 72, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  21100\n",
      "training @ iter =  21200\n",
      "training @ iter =  21300\n",
      "epoch 73, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  21400\n",
      "training @ iter =  21500\n",
      "training @ iter =  21600\n",
      "epoch 74, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  21700\n",
      "training @ iter =  21800\n",
      "training @ iter =  21900\n",
      "epoch 75, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  22000\n",
      "training @ iter =  22100\n",
      "training @ iter =  22200\n",
      "epoch 76, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  22300\n",
      "training @ iter =  22400\n",
      "training @ iter =  22500\n",
      "epoch 77, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  22600\n",
      "training @ iter =  22700\n",
      "training @ iter =  22800\n",
      "epoch 78, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  22900\n",
      "training @ iter =  23000\n",
      "training @ iter =  23100\n",
      "epoch 79, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  23200\n",
      "training @ iter =  23300\n",
      "training @ iter =  23400\n",
      "epoch 80, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  23500\n",
      "training @ iter =  23600\n",
      "training @ iter =  23700\n",
      "epoch 81, minibatch 293/293, validation error 1.095238 %\n",
      "training @ iter =  23800\n",
      "training @ iter =  23900\n",
      "training @ iter =  24000\n",
      "epoch 82, minibatch 293/293, validation error 1.107143 %\n",
      "training @ iter =  24100\n",
      "training @ iter =  24200\n",
      "training @ iter =  24300\n",
      "epoch 83, minibatch 293/293, validation error 1.107143 %\n",
      "training @ iter =  24400\n",
      "training @ iter =  24500\n",
      "training @ iter =  24600\n",
      "Optimization complete.\n",
      "Best validation score of 1.071429 % obtained at iteration 16701, with test performance 1.261905 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file CNN.py ran for 6.33m\n"
     ]
    }
   ],
   "source": [
    "%aimport nn_modules.CNN\n",
    "\n",
    "hidden_layer_list = []\n",
    "validate_list = []\n",
    "batch_list = []\n",
    "\n",
    "\n",
    "for n_batch in [1]:\n",
    "    for n_hidden in [1]:\n",
    "        hidden_layer_list.append(n_hidden)\n",
    "        batch_list.append(n_batch)\n",
    "        \n",
    "        print n_batch\n",
    "        \n",
    "        image_size = (28, 28)\n",
    "        pool_sizes = [(2, 2), (2, 2)]\n",
    "        filter_sizes = [(5,5), (5,5)]\n",
    "        nkerns = [20, 50]\n",
    "        n_epochs = 100\n",
    "    \n",
    "        cnn = nn_modules.CNN.CNN(nkerns=nkerns, batch_size=100, image_size=image_size, pool_sizes=pool_sizes, filter_sizes=filter_sizes, n_epochs=n_epochs)\n",
    "        validate_loss = cnn.train(datasets)\n",
    "        \n",
    "        validate_list.append(validate_loss)\n",
    "        \n",
    "        write_bias_variance_data(\"cnn.csv\", hidden_layer_list, batch_list, validate_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200L, 784L)\n",
      "4147\n",
      "53\n",
      "98.7380952381 %\n"
     ]
    }
   ],
   "source": [
    "print test_set[0].shape\n",
    "\n",
    "predicted = cnn.predict(test_set[0].astype(theano.config.floatX))\n",
    "label = test_set[1]\n",
    "\n",
    "\n",
    "s=0\n",
    "f=0\n",
    "for p, l in zip(predicted, label):\n",
    "    if p == l:\n",
    "        s += 1\n",
    "    else:\n",
    "        f += 1\n",
    "        \n",
    "print s\n",
    "print f\n",
    "print float(s)/(s+f)*100,\n",
    "print '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/test.csv', header=0);\n",
    "predicted = cnn.predict(data.astype(theano.config.floatX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([numpy.arange(1, data.shape[0]+1), predicted]).T\n",
    "df.columns = ['ImageId', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"result.csv\", cols=['ImageId', 'Label'], index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = (28, 28)\n",
    "pool_sizes = [(2, 2), (2, 2)]\n",
    "filter_sizes = [(5,5), (5,5)]\n",
    "nkerns = [20, 50]\n",
    "n_epochs = 100\n",
    "\n",
    "cnn = nn_modules.CNN.CNN(nkerns=nkerns, batch_size=100, image_size=image_size, pool_sizes=pool_sizes, filter_sizes=filter_sizes, n_epochs=n_epochs)\n",
    "\n",
    "data = pd.read_csv('data/test.csv', header=0);\n",
    "predicted = cnn.predict(data.astype(theano.config.floatX))\n",
    "\n",
    "df = pd.DataFrame([numpy.arange(1, data.shape[0]+1), predicted]).T\n",
    "df.columns = ['ImageId', 'Label']\n",
    "\n",
    "df.to_csv(\"result.csv\", cols=['ImageId', 'Label'], index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pylab\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# open random image of dimensions 639x516\n",
    "img = Image.open(open('data/5_684.bmp'))\n",
    "#img = numpy.asarray(img, dtype='float64') / 256.\n",
    "img = numpy.asarray(img, dtype='float')\n",
    "\n",
    "_img = img.reshape(1, 784)\n",
    "_img = numpy.apply_over_axes((lambda x,axis:x>0), _img, [0])\n",
    "\n",
    "f = theano.function([cnn.x], cnn.layers[0][0].output)\n",
    "\n",
    "# put image in 4D tensor of shape (1, 3, height, width)\n",
    "filtered_img = f(_img)\n",
    "\n",
    "# plot original image and first and second components of output\n",
    "pylab.subplot(1, 3, 1); pylab.axis('off'); pylab.imshow(img)\n",
    "pylab.gray();\n",
    "# recall that the convOp output (filtered image) is actually a \"minibatch\",\n",
    "# of size 1 here, so we take index 0 in the first dimension:\n",
    "pylab.subplot(1, 3, 2); pylab.axis('off'); pylab.imshow(filtered_img[0, 0, :, :])\n",
    "pylab.subplot(1, 3, 3); pylab.axis('off'); pylab.imshow(filtered_img[0, 1, :, :])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
